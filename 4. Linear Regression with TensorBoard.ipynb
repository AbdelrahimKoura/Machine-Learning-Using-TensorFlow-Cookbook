{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable eager execution\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the TensorFlow way of linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "housing_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\n",
    "path = tf.keras.utils.get_file(housing_url.split(\"/\")[-1], housing_url)\n",
    "\n",
    "columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "data = pd.read_table(path, delim_whitespace=True, header=None, names=columns)\n",
    "\n",
    "np.random.seed(1)\n",
    "train = data.sample(frac=0.8).copy()\n",
    "y_train = train['MEDV']\n",
    "train.drop('MEDV', axis=1, inplace=True)\n",
    "\n",
    "test = data.loc[~data.index.isin(train.index)].copy()\n",
    "y_test = test['MEDV']\n",
    "test.drop('MEDV', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_feature_columns(data_df, categorical_cols, numeric_cols):\n",
    "    feature_columns = []\n",
    "    \n",
    "    for feature_name in numeric_cols:\n",
    "        feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
    "    \n",
    "    for feature_name in categorical_cols:\n",
    "        vocabulary = data_df[feature_name].unique()\n",
    "        feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "\n",
    "    return feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=256):\n",
    "    \n",
    "    def input_function():\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000)\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "        return ds\n",
    "    \n",
    "    return input_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['CHAS', 'RAD']\n",
    "numeric_cols = ['CRIM', 'ZN', 'INDUS',  'NOX', 'RM', 'AGE', 'DIS', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "feature_columns = define_feature_columns(data, categorical_cols, numeric_cols)\n",
    "\n",
    "train_input_fn = make_input_fn(train, y_train, num_epochs=1400)\n",
    "test_input_fn = make_input_fn(test, y_test, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './logs/', '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000000000F84BE88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:518: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\ftrl.py:143: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./logs/model.ckpt.\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Failed to create a NewWriteableFile: ./logs/model.ckpt-0_temp_32134ed522e140a5bcd67b7843a8b290/part-00000-of-00001.data-00000-of-00001.tempstate15754753703399400385 : Impossibile trovare il percorso specificato.\r\n; No such process\n\t [[node save/SaveV2 (defined at C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]]\n\nOriginal stack trace for 'save/SaveV2':\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 153, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\asyncio\\base_events.py\", line 538, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\asyncio\\base_events.py\", line 1782, in _run_once\n    handle._run()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-1a723ee1def0>\", line 5, in <module>\n    linear_est.train(train_input_fn)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 370, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1160, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1194, in _train_model_default\n    saving_listeners)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1489, in _train_with_estimator_spec\n    log_step_count_steps=log_step_count_steps) as mon_sess:\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\", line 584, in MonitoredTrainingSession\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\", line 1014, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\", line 725, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\", line 1207, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\", line 1212, in _create_session\n    return self._sess_creator.create_session()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\", line 878, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\", line 638, in create_session\n    self._scaffold.finalize()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\", line 237, in finalize\n    self._saver.build()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\", line 840, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\", line 878, in _build\n    build_restore=build_restore)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\", line 499, in _build_internal\n    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\", line 291, in _AddShardedSaveOps\n    return self._AddShardedSaveOpsForV2(filename_tensor, per_device)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\", line 265, in _AddShardedSaveOpsForV2\n    sharded_saves.append(self._AddSaveOps(sharded_filename, saveables))\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\", line 206, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\", line 122, in save_op\n    tensors)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_io_ops.py\", line 1945, in save_v2\n    name=name)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 793, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3360, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3429, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1751, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Failed to create a NewWriteableFile: ./logs/model.ckpt-0_temp_32134ed522e140a5bcd67b7843a8b290/part-00000-of-00001.data-00000-of-00001.tempstate15754753703399400385 : Impossibile trovare il percorso specificato.\r\n; No such process\n\t [[{{node save/SaveV2}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1a723ee1def0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                           \u001b[0mmodel_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                           config=tf.estimator.RunConfig().replace(save_summary_steps=10))\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlinear_est\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_est\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_input_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1158\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1160\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1192\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0;32m   1193\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1194\u001b[1;33m                                              saving_listeners)\n\u001b[0m\u001b[0;32m   1195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[1;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[0;32m   1487\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_config\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m         \u001b[0mmax_wait_secs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession_creation_timeout_secs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m         log_step_count_steps=log_step_count_steps) as mon_sess:\n\u001b[0m\u001b[0;32m   1490\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mMonitoredTrainingSession\u001b[1;34m(master, is_chief, checkpoint_dir, scaffold, hooks, chief_only_hooks, save_checkpoint_secs, save_summaries_steps, save_summaries_secs, config, stop_grace_period_secs, log_step_count_steps, max_wait_secs, save_checkpoint_steps, summary_dir)\u001b[0m\n\u001b[0;32m    582\u001b[0m       \u001b[0msession_creator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession_creator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m       stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[0mshould_recover\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[0;32m    723\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0;32m    724\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    726\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sess_creator)\u001b[0m\n\u001b[0;32m   1205\u001b[0m     \"\"\"\n\u001b[0;32m   1206\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m     \u001b[0m_WrappedSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1210\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1212\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1213\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m         logging.info(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    883\u001b[0m       \u001b[1;31m# Inform the hooks that a new session has been created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mhook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_create_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_sess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m       return _CoordinatedSession(\n\u001b[0;32m    887\u001b[0m           \u001b[0m_HookedSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_sess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoord\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\basic_session_run_hooks.py\u001b[0m in \u001b[0;36mafter_create_session\u001b[1;34m(self, session, coord)\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_summary_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_meta_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;31m# The checkpoint saved here is the state at step \"global_step\".\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_last_triggered_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\basic_session_run_hooks.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(self, session, step)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_saver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     self._summary_writer.add_session_log(\n\u001b[0;32m    613\u001b[0m         SessionLog(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs, save_debug_info)\u001b[0m\n\u001b[0;32m   1191\u001b[0m               \"Parent directory of {} doesn't exist, can't save.\".format(\n\u001b[0;32m   1192\u001b[0m                   save_path))\n\u001b[1;32m-> 1193\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrite_meta_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs, save_debug_info)\u001b[0m\n\u001b[0;32m   1174\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[0;32m   1175\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m         \u001b[0mmodel_checkpoint_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1384\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Failed to create a NewWriteableFile: ./logs/model.ckpt-0_temp_32134ed522e140a5bcd67b7843a8b290/part-00000-of-00001.data-00000-of-00001.tempstate15754753703399400385 : Impossibile trovare il percorso specificato.\r\n; No such process\n\t [[node save/SaveV2 (defined at C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]]\n\nOriginal stack trace for 'save/SaveV2':\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 153, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\asyncio\\base_events.py\", line 538, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\asyncio\\base_events.py\", line 1782, in _run_once\n    handle._run()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-1a723ee1def0>\", line 5, in <module>\n    linear_est.train(train_input_fn)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 370, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1160, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1194, in _train_model_default\n    saving_listeners)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1489, in _train_with_estimator_spec\n    log_step_count_steps=log_step_count_steps) as mon_sess:\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\", line 584, in MonitoredTrainingSession\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\", line 1014, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\", line 725, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\", line 1207, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\", line 1212, in _create_session\n    return self._sess_creator.create_session()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\", line 878, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\", line 638, in create_session\n    self._scaffold.finalize()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\", line 237, in finalize\n    self._saver.build()\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\", line 840, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\", line 878, in _build\n    build_restore=build_restore)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\", line 499, in _build_internal\n    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\", line 291, in _AddShardedSaveOps\n    return self._AddShardedSaveOpsForV2(filename_tensor, per_device)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\", line 265, in _AddShardedSaveOpsForV2\n    sharded_saves.append(self._AddSaveOps(sharded_filename, saveables))\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\", line 206, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\", line 122, in save_op\n    tensors)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_io_ops.py\", line 1945, in save_v2\n    name=name)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 793, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3360, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3429, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\Luca\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1751, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "output_dir = './logs/'\n",
    "linear_est = tf.estimator.LinearRegressor(feature_columns=feature_columns,\n",
    "                                          model_dir = output_dir,\n",
    "                                          config=tf.estimator.RunConfig().replace(save_summary_steps=10))\n",
    "linear_est.train(train_input_fn)\n",
    "result = linear_est.evaluate(test_input_fn)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./model_LinearRegressor\n",
    "# http://localhost:6006/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmppo3n7koe\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\LUCAMA~1.AZU\\\\AppData\\\\Local\\\\Temp\\\\tmppo3n7koe', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmppo3n7koe\\model.ckpt.\n",
      "INFO:tensorflow:loss = 599.6019, step = 0\n",
      "INFO:tensorflow:global_step/sec: 99.108\n",
      "INFO:tensorflow:loss = 61.533295, step = 100 (1.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.875\n",
      "INFO:tensorflow:loss = 45.466507, step = 200 (0.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.155\n",
      "INFO:tensorflow:loss = 43.114693, step = 300 (0.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.686\n",
      "INFO:tensorflow:loss = 46.802444, step = 400 (0.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.009\n",
      "INFO:tensorflow:loss = 43.78224, step = 500 (0.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.144\n",
      "INFO:tensorflow:loss = 46.781265, step = 600 (0.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.607\n",
      "INFO:tensorflow:loss = 36.33243, step = 700 (0.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.279\n",
      "INFO:tensorflow:loss = 35.84384, step = 800 (0.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.009\n",
      "INFO:tensorflow:loss = 35.258484, step = 900 (0.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.811\n",
      "INFO:tensorflow:loss = 35.408417, step = 1000 (0.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.279\n",
      "INFO:tensorflow:loss = 34.536106, step = 1100 (0.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.473\n",
      "INFO:tensorflow:loss = 37.156, step = 1200 (0.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.34\n",
      "INFO:tensorflow:loss = 39.137352, step = 1300 (0.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.875\n",
      "INFO:tensorflow:loss = 32.179695, step = 1400 (0.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.144\n",
      "INFO:tensorflow:loss = 31.747593, step = 1500 (0.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.025\n",
      "INFO:tensorflow:loss = 30.670023, step = 1600 (0.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.679\n",
      "INFO:tensorflow:loss = 31.445177, step = 1700 (0.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.279\n",
      "INFO:tensorflow:loss = 32.453747, step = 1800 (0.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.009\n",
      "INFO:tensorflow:loss = 38.56798, step = 1900 (0.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.474\n",
      "INFO:tensorflow:loss = 30.824871, step = 2000 (0.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.55\n",
      "INFO:tensorflow:loss = 27.707157, step = 2100 (0.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.474\n",
      "INFO:tensorflow:loss = 32.414036, step = 2200 (0.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.207\n",
      "INFO:tensorflow:loss = 36.803207, step = 2300 (0.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.279\n",
      "INFO:tensorflow:loss = 32.08618, step = 2400 (0.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.507\n",
      "INFO:tensorflow:loss = 32.732693, step = 2500 (0.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.766\n",
      "INFO:tensorflow:loss = 29.200062, step = 2600 (0.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.81\n",
      "INFO:tensorflow:loss = 25.368385, step = 2700 (0.871 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2800 into C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmppo3n7koe\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 30.162722.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-11T15:48:49Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmppo3n7koe\\model.ckpt-2800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.50200s\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-11-15:48:49\n",
      "INFO:tensorflow:Saving dict for global step 2800: average_loss = 31.210018, global_step = 2800, label/mean = 22.048513, loss = 31.210018, prediction/mean = 21.472042\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2800: C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmppo3n7koe\\model.ckpt-2800\n",
      "{'average_loss': 31.210018, 'label/mean': 22.048513, 'loss': 31.210018, 'prediction/mean': 21.472042, 'global_step': 2800}\n"
     ]
    }
   ],
   "source": [
    "def create_interactions(interactions_list, buckets=5):\n",
    "    interactions = list()\n",
    "    for (a, b) in interactions_list:\n",
    "        interactions.append(tf.feature_column.crossed_column([a, b], hash_bucket_size=buckets))\n",
    "    return interactions\n",
    "\n",
    "derived_feature_columns = create_interactions([['RM', 'LSTAT']])\n",
    "linear_est = tf.estimator.LinearRegressor(feature_columns=feature_columns+derived_feature_columns)\n",
    "linear_est.train(train_input_fn)\n",
    "result = linear_est.evaluate(test_input_fn)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmppo3n7koe\\model.ckpt-2800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[[24.966026 ]\n",
      " [30.792831 ]\n",
      " [19.965616 ]\n",
      " [21.705784 ]\n",
      " [17.92263  ]\n",
      " [16.969158 ]\n",
      " [18.44628  ]\n",
      " [12.594122 ]\n",
      " [23.609722 ]\n",
      " [25.41783  ]\n",
      " [20.988722 ]\n",
      " [17.235489 ]\n",
      " [28.785534 ]\n",
      " [17.020382 ]\n",
      " [19.86322  ]\n",
      " [21.126266 ]\n",
      " [24.21743  ]\n",
      " [22.958235 ]\n",
      " [24.634926 ]\n",
      " [22.927227 ]\n",
      " [26.600338 ]\n",
      " [25.359941 ]\n",
      " [22.940815 ]\n",
      " [19.385841 ]\n",
      " [21.221813 ]\n",
      " [11.892557 ]\n",
      " [17.621983 ]\n",
      " [21.431473 ]\n",
      " [20.321741 ]\n",
      " [ 5.909903 ]\n",
      " [13.214111 ]\n",
      " [10.251263 ]\n",
      " [19.87257  ]\n",
      " [19.319813 ]\n",
      " [15.361031 ]\n",
      " [33.667297 ]\n",
      " [27.610998 ]\n",
      " [28.950027 ]\n",
      " [34.075428 ]\n",
      " [34.0354   ]\n",
      " [34.79254  ]\n",
      " [15.712332 ]\n",
      " [20.279564 ]\n",
      " [24.00077  ]\n",
      " [36.459587 ]\n",
      " [26.322544 ]\n",
      " [32.52994  ]\n",
      " [24.587467 ]\n",
      " [20.381908 ]\n",
      " [22.71426  ]\n",
      " [27.30598  ]\n",
      " [24.80653  ]\n",
      " [23.983034 ]\n",
      " [30.146404 ]\n",
      " [23.703812 ]\n",
      " [23.647013 ]\n",
      " [33.180866 ]\n",
      " [27.711115 ]\n",
      " [32.852333 ]\n",
      " [27.764217 ]\n",
      " [36.000305 ]\n",
      " [25.562262 ]\n",
      " [15.781063 ]\n",
      " [26.519505 ]\n",
      " [24.669838 ]\n",
      " [15.671539 ]\n",
      " [18.274097 ]\n",
      " [19.03414  ]\n",
      " [23.360828 ]\n",
      " [24.430035 ]\n",
      " [27.460808 ]\n",
      " [23.060722 ]\n",
      " [23.149773 ]\n",
      " [26.542778 ]\n",
      " [13.090664 ]\n",
      " [24.60595  ]\n",
      " [19.230953 ]\n",
      " [ 4.7310753]\n",
      " [ 6.5078545]\n",
      " [20.628416 ]\n",
      " [18.5453   ]\n",
      " [20.855915 ]\n",
      " [20.46202  ]\n",
      " [20.483425 ]\n",
      " [ 7.826874 ]\n",
      " [17.619549 ]\n",
      " [11.774929 ]\n",
      " [12.5722885]\n",
      " [ 8.484125 ]\n",
      " [14.558523 ]\n",
      " [19.94373  ]\n",
      " [18.268606 ]\n",
      " [20.952997 ]\n",
      " [17.88831  ]\n",
      " [16.34632  ]\n",
      " [19.56686  ]\n",
      " [22.196712 ]\n",
      " [13.077761 ]\n",
      " [21.584198 ]\n",
      " [13.711571 ]\n",
      " [19.569683 ]]\n"
     ]
    }
   ],
   "source": [
    "def dicts_to_preds(pred_dicts):\n",
    "    return np.array([pred['predictions'] for pred in pred_dicts])\n",
    "\n",
    "preds = dicts_to_preds(linear_est.predict(test_input_fn))\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras to estimator version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_feature_columns_layers(data_df, categorical_cols, numeric_cols):\n",
    "    feature_columns = []\n",
    "    feature_layer_inputs = {}\n",
    "    \n",
    "    for feature_name in numeric_cols:\n",
    "        feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
    "        feature_layer_inputs[feature_name] = tf.keras.Input(shape=(1,), name=feature_name)\n",
    "        \n",
    "    for feature_name in categorical_cols:\n",
    "        vocabulary = data_df[feature_name].unique()\n",
    "        cat = tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)\n",
    "        cat_one_hot = tf.feature_column.indicator_column(cat)\n",
    "        feature_columns.append(cat_one_hot)\n",
    "        feature_layer_inputs[feature_name] = tf.keras.Input(shape=(1,), name=feature_name, dtype=tf.int32)\n",
    "    \n",
    "    return feature_columns, feature_layer_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interactions(interactions_list, buckets=5):\n",
    "    feature_columns = []\n",
    "    \n",
    "    for (a, b) in interactions_list:\n",
    "        crossed_feature = tf.feature_column.crossed_column([a, b], hash_bucket_size=buckets)\n",
    "        crossed_feature_one_hot = tf.feature_column.indicator_column(crossed_feature)\n",
    "        feature_columns.append(crossed_feature_one_hot)\n",
    "        \n",
    "    return feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linreg(feature_columns, feature_layer_inputs, optimizer):\n",
    "\n",
    "    feature_layer = keras.layers.DenseFeatures(feature_columns)\n",
    "    feature_layer_outputs = feature_layer(feature_layer_inputs)\n",
    "    norm = keras.layers.BatchNormalization()(feature_layer_outputs)\n",
    "    outputs = keras.layers.Dense(1, kernel_initializer='normal', activation='linear')(norm)\n",
    "    \n",
    "    model = keras.Model(inputs=[v for v in feature_layer_inputs.values()], outputs=outputs)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LucaMassaron.AzureAD\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From C:\\Users\\LucaMassaron.AzureAD\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4322: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From C:\\Users\\LucaMassaron.AzureAD\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4322: CrossedColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = ['CHAS', 'RAD']\n",
    "numeric_cols = ['CRIM', 'ZN', 'INDUS',  'NOX', 'RM', 'AGE', 'DIS', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "feature_columns, feature_layer_inputs = define_feature_columns_layers(data, categorical_cols, numeric_cols)\n",
    "interactions_columns = create_interactions([['RM', 'LSTAT']])\n",
    "\n",
    "feature_columns += interactions_columns\n",
    "\n",
    "optimizer = keras.optimizers.Ftrl(learning_rate=0.02)\n",
    "model = create_linreg(feature_columns, feature_layer_inputs, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\LUCAMA~1.AZU\\\\AppData\\\\Local\\\\Temp\\\\tmpv_bcjh72', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "def canned_keras(model):\n",
    "    model_dir = tempfile.mkdtemp()\n",
    "    keras_estimator = tf.keras.estimator.model_to_estimator(\n",
    "        keras_model=model, model_dir=model_dir)\n",
    "    return keras_estimator\n",
    "\n",
    "estimator = canned_keras(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='C:\\\\Users\\\\LUCAMA~1.AZU\\\\AppData\\\\Local\\\\Temp\\\\tmpv_bcjh72\\\\keras\\\\keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmpv_bcjh72\\keras\\keras_model.ckpt\n",
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n",
      "INFO:tensorflow:Warm-started 4 variables.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmpv_bcjh72\\model.ckpt.\n",
      "INFO:tensorflow:loss = 605.7178, step = 0\n",
      "INFO:tensorflow:global_step/sec: 195.312\n",
      "INFO:tensorflow:loss = 300.6946, step = 100 (0.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.311\n",
      "INFO:tensorflow:loss = 135.90347, step = 200 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.719\n",
      "INFO:tensorflow:loss = 66.50286, step = 300 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.717\n",
      "INFO:tensorflow:loss = 43.682396, step = 400 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.781\n",
      "INFO:tensorflow:loss = 37.390614, step = 500 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.244\n",
      "INFO:tensorflow:loss = 34.460136, step = 600 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.273\n",
      "INFO:tensorflow:loss = 31.876295, step = 700 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.225\n",
      "INFO:tensorflow:loss = 33.97641, step = 800 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.225\n",
      "INFO:tensorflow:loss = 27.277843, step = 900 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.245\n",
      "INFO:tensorflow:loss = 32.77341, step = 1000 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.718\n",
      "INFO:tensorflow:loss = 28.245209, step = 1100 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.245\n",
      "INFO:tensorflow:loss = 26.580795, step = 1200 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.244\n",
      "INFO:tensorflow:loss = 26.08232, step = 1300 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.717\n",
      "INFO:tensorflow:loss = 30.70565, step = 1400 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.719\n",
      "INFO:tensorflow:loss = 26.126682, step = 1500 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.79\n",
      "INFO:tensorflow:loss = 29.294155, step = 1600 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.758\n",
      "INFO:tensorflow:loss = 25.441984, step = 1700 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.215\n",
      "INFO:tensorflow:loss = 27.801786, step = 1800 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.72\n",
      "INFO:tensorflow:loss = 21.108065, step = 1900 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.733\n",
      "INFO:tensorflow:loss = 25.922766, step = 2000 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.357\n",
      "INFO:tensorflow:loss = 26.147903, step = 2100 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.225\n",
      "INFO:tensorflow:loss = 24.814575, step = 2200 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.273\n",
      "INFO:tensorflow:loss = 25.165686, step = 2300 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.733\n",
      "INFO:tensorflow:loss = 24.752129, step = 2400 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.819\n",
      "INFO:tensorflow:loss = 17.477154, step = 2500 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.273\n",
      "INFO:tensorflow:loss = 24.272633, step = 2600 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.734\n",
      "INFO:tensorflow:loss = 21.28677, step = 2700 (0.443 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2800 into C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmpv_bcjh72\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 25.494072.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-11T15:49:08Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmpv_bcjh72\\model.ckpt-2800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.24400s\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-11-15:49:08\n",
      "INFO:tensorflow:Saving dict for global step 2800: global_step = 2800, loss = 25.160828\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2800: C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmpv_bcjh72\\model.ckpt-2800\n",
      "{'loss': 25.160828, 'global_step': 2800}\n"
     ]
    }
   ],
   "source": [
    "train_input_fn = make_input_fn(train, y_train, num_epochs=1400)\n",
    "test_input_fn = make_input_fn(test, y_test, num_epochs=1, shuffle=False)\n",
    "\n",
    "estimator.train(train_input_fn)\n",
    "result = estimator.evaluate(test_input_fn)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding coefficients in linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = estimator.get_variable_value('layer_with_weights-1/kernel/.ATTRIBUTES/VARIABLE_VALUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01552782]\n",
      " [ 0.07513991]\n",
      " [-0.05228834]\n",
      " [-0.0862719 ]\n",
      " [-0.01169319]\n",
      " [ 0.00709739]\n",
      " [ 0.08730743]\n",
      " [-0.00230968]\n",
      " [ 0.02895174]\n",
      " [ 0.06118769]\n",
      " [ 0.05902488]\n",
      " [-0.13423888]\n",
      " [-0.02005083]\n",
      " [ 0.01062155]\n",
      " [ 0.02191463]\n",
      " [ 0.05915826]\n",
      " [-0.03479118]\n",
      " [ 0.05837935]\n",
      " [ 0.04497513]\n",
      " [-0.00108679]\n",
      " [ 0.15156531]\n",
      " [-0.01708724]\n",
      " [-0.06367704]\n",
      " [ 0.00842286]\n",
      " [ 0.0287493 ]\n",
      " [ 0.06794064]\n",
      " [ 0.02151924]]\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(feature_columns):\n",
    "    labels = list()\n",
    "    for col in feature_columns:\n",
    "        col_config = col.get_config()\n",
    "        if 'key' in col_config:\n",
    "            labels.append(col_config['key'])\n",
    "        elif 'categorical_column' in col_config:\n",
    "            if col_config['categorical_column']['class_name']=='VocabularyListCategoricalColumn':\n",
    "                key = col_config['categorical_column']['config']['key']\n",
    "                for item in col_config['categorical_column']['config']['vocabulary_list']:\n",
    "                     labels.append(key+'_val='+str(item))\n",
    "            elif col_config['categorical_column']['class_name']=='CrossedColumn':\n",
    "                keys = col_config['categorical_column']['config']['keys']\n",
    "                for bucket in range(col_config['categorical_column']['config']['hash_bucket_size']):\n",
    "                    labels.append('x'.join(keys)+'_bkt_'+str(bucket))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM            : +0.02\n",
      "ZN              : +0.08\n",
      "INDUS           : -0.05\n",
      "NOX             : -0.09\n",
      "RM              : -0.01\n",
      "AGE             : +0.01\n",
      "DIS             : +0.09\n",
      "TAX             : -0.00\n",
      "PTRATIO         : +0.03\n",
      "B               : +0.06\n",
      "LSTAT           : +0.06\n",
      "CHAS_val=0      : -0.13\n",
      "CHAS_val=1      : -0.02\n",
      "RAD_val=1       : +0.01\n",
      "RAD_val=2       : +0.02\n",
      "RAD_val=3       : +0.06\n",
      "RAD_val=5       : -0.03\n",
      "RAD_val=4       : +0.06\n",
      "RAD_val=8       : +0.04\n",
      "RAD_val=6       : -0.00\n",
      "RAD_val=7       : +0.15\n",
      "RAD_val=24      : -0.02\n",
      "RMxLSTAT_bkt_0  : -0.06\n",
      "RMxLSTAT_bkt_1  : +0.01\n",
      "RMxLSTAT_bkt_2  : +0.03\n",
      "RMxLSTAT_bkt_3  : +0.07\n",
      "RMxLSTAT_bkt_4  : +0.02\n"
     ]
    }
   ],
   "source": [
    "labels = extract_labels(feature_columns)\n",
    "\n",
    "for label, weight in zip(labels, weights):\n",
    "    print(f\"{label:15s} : {weight[0]:+.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding loss functions in linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linreg(feature_columns, feature_layer_inputs, optimizer, \n",
    "                  loss='mean_squared_error', metrics=['mean_absolute_error']):\n",
    "\n",
    "    feature_layer = keras.layers.DenseFeatures(feature_columns)\n",
    "    feature_layer_outputs = feature_layer(feature_layer_inputs)\n",
    "    norm = keras.layers.BatchNormalization()(feature_layer_outputs)\n",
    "    outputs = keras.layers.Dense(1, kernel_initializer='normal', activation='linear')(norm)\n",
    "    \n",
    "    model = keras.Model(inputs=[v for v in feature_layer_inputs.values()], outputs=outputs)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\LUCAMA~1.AZU\\\\AppData\\\\Local\\\\Temp\\\\tmpsovirc_0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='C:\\\\Users\\\\LUCAMA~1.AZU\\\\AppData\\\\Local\\\\Temp\\\\tmpsovirc_0\\\\keras\\\\keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmpsovirc_0\\keras\\keras_model.ckpt\n",
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n",
      "INFO:tensorflow:Warm-started 4 variables.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmpsovirc_0\\model.ckpt.\n",
      "INFO:tensorflow:loss = 22.744534, step = 0\n",
      "INFO:tensorflow:global_step/sec: 196.078\n",
      "INFO:tensorflow:loss = 21.11842, step = 100 (0.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.719\n",
      "INFO:tensorflow:loss = 14.331498, step = 200 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.734\n",
      "INFO:tensorflow:loss = 7.6268196, step = 300 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.73\n",
      "INFO:tensorflow:loss = 3.8572695, step = 400 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.225\n",
      "INFO:tensorflow:loss = 4.284394, step = 500 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.719\n",
      "INFO:tensorflow:loss = 4.040914, step = 600 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.225\n",
      "INFO:tensorflow:loss = 3.9930973, step = 700 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.719\n",
      "INFO:tensorflow:loss = 3.8286324, step = 800 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.718\n",
      "INFO:tensorflow:loss = 3.6313248, step = 900 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.733\n",
      "INFO:tensorflow:loss = 3.7774153, step = 1000 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.78\n",
      "INFO:tensorflow:loss = 3.5157452, step = 1100 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.758\n",
      "INFO:tensorflow:loss = 3.372046, step = 1200 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.734\n",
      "INFO:tensorflow:loss = 3.7121885, step = 1300 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.481\n",
      "INFO:tensorflow:loss = 3.440843, step = 1400 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.61\n",
      "INFO:tensorflow:loss = 2.984778, step = 1500 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.82\n",
      "INFO:tensorflow:loss = 3.5172741, step = 1600 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.729\n",
      "INFO:tensorflow:loss = 3.4917765, step = 1700 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.818\n",
      "INFO:tensorflow:loss = 2.9490492, step = 1800 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.714\n",
      "INFO:tensorflow:loss = 2.943399, step = 1900 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.517\n",
      "INFO:tensorflow:loss = 3.1814816, step = 2000 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.734\n",
      "INFO:tensorflow:loss = 2.9785712, step = 2100 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.273\n",
      "INFO:tensorflow:loss = 3.298603, step = 2200 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.245\n",
      "INFO:tensorflow:loss = 2.950315, step = 2300 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.757\n",
      "INFO:tensorflow:loss = 3.1514375, step = 2400 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.222\n",
      "INFO:tensorflow:loss = 2.558793, step = 2500 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.225\n",
      "INFO:tensorflow:loss = 3.2934914, step = 2600 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.791\n",
      "INFO:tensorflow:loss = 3.0562158, step = 2700 (0.439 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2800 into C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmpsovirc_0\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.887368.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-11T15:51:21Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmpsovirc_0\\model.ckpt-2800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.24900s\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-11-15:51:21\n",
      "INFO:tensorflow:Saving dict for global step 2800: global_step = 2800, loss = 3.1208777, mean_absolute_error = 3.1208777, mean_squared_error = 27.170328\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2800: C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmpsovirc_0\\model.ckpt-2800\n",
      "{'loss': 3.1208777, 'mean_absolute_error': 3.1208777, 'mean_squared_error': 27.170328, 'global_step': 2800}\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = ['CHAS', 'RAD']\n",
    "numeric_cols = ['CRIM', 'ZN', 'INDUS',  'NOX', 'RM', 'AGE', 'DIS', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "feature_columns, feature_layer_inputs = define_feature_columns_layers(data, categorical_cols, numeric_cols)\n",
    "interactions_columns = create_interactions([['RM', 'LSTAT']])\n",
    "\n",
    "feature_columns += interactions_columns\n",
    "\n",
    "optimizer = keras.optimizers.Ftrl(learning_rate=0.02)\n",
    "model = create_linreg(feature_columns, feature_layer_inputs, optimizer,\n",
    "                      loss='mean_absolute_error', \n",
    "                      metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "\n",
    "estimator = canned_keras(model)\n",
    "\n",
    "train_input_fn = make_input_fn(train, y_train, num_epochs=1400)\n",
    "test_input_fn = make_input_fn(test, y_test, num_epochs=1, shuffle=False)\n",
    "\n",
    "estimator.train(train_input_fn)\n",
    "result = estimator.evaluate(test_input_fn)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing lasso and ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ridge_linreg(feature_columns, feature_layer_inputs, optimizer, \n",
    "                        loss='mean_squared_error', metrics=['mean_absolute_error'],\n",
    "                        l2=0.01):\n",
    "    \n",
    "    regularizer = keras.regularizers.l2(l2)\n",
    "\n",
    "    feature_layer = keras.layers.DenseFeatures(feature_columns)\n",
    "    feature_layer_outputs = feature_layer(feature_layer_inputs)\n",
    "    norm = keras.layers.BatchNormalization()(feature_layer_outputs)\n",
    "    outputs = keras.layers.Dense(1, \n",
    "                                 kernel_initializer='normal', \n",
    "                                 kernel_regularizer = regularizer, \n",
    "                                 activation='linear')(norm)\n",
    "    \n",
    "    model = keras.Model(inputs=[v for v in feature_layer_inputs.values()], outputs=outputs)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\LUCAMA~1.AZU\\\\AppData\\\\Local\\\\Temp\\\\tmpznihab50', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='C:\\\\Users\\\\LUCAMA~1.AZU\\\\AppData\\\\Local\\\\Temp\\\\tmpznihab50\\\\keras\\\\keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmpznihab50\\keras\\keras_model.ckpt\n",
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n",
      "INFO:tensorflow:Warm-started 4 variables.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmpznihab50\\model.ckpt.\n",
      "INFO:tensorflow:loss = 578.79803, step = 0\n",
      "INFO:tensorflow:global_step/sec: 198.808\n",
      "INFO:tensorflow:loss = 306.91296, step = 100 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.733\n",
      "INFO:tensorflow:loss = 137.25328, step = 200 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.239\n",
      "INFO:tensorflow:loss = 60.530792, step = 300 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.273\n",
      "INFO:tensorflow:loss = 48.93827, step = 400 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.215\n",
      "INFO:tensorflow:loss = 39.30263, step = 500 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.245\n",
      "INFO:tensorflow:loss = 32.455917, step = 600 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.215\n",
      "INFO:tensorflow:loss = 30.175236, step = 700 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.272\n",
      "INFO:tensorflow:loss = 28.2101, step = 800 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.72\n",
      "INFO:tensorflow:loss = 32.96273, step = 900 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.719\n",
      "INFO:tensorflow:loss = 36.93371, step = 1000 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.214\n",
      "INFO:tensorflow:loss = 29.536821, step = 1100 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.215\n",
      "INFO:tensorflow:loss = 31.491318, step = 1200 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.757\n",
      "INFO:tensorflow:loss = 28.245861, step = 1300 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.214\n",
      "INFO:tensorflow:loss = 26.327719, step = 1400 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.215\n",
      "INFO:tensorflow:loss = 31.335331, step = 1500 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.272\n",
      "INFO:tensorflow:loss = 23.295738, step = 1600 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.225\n",
      "INFO:tensorflow:loss = 28.188103, step = 1700 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.833\n",
      "INFO:tensorflow:loss = 29.112068, step = 1800 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.214\n",
      "INFO:tensorflow:loss = 26.218384, step = 1900 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.758\n",
      "INFO:tensorflow:loss = 27.845562, step = 2000 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.215\n",
      "INFO:tensorflow:loss = 15.269224, step = 2100 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.734\n",
      "INFO:tensorflow:loss = 22.419233, step = 2200 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.272\n",
      "INFO:tensorflow:loss = 23.622625, step = 2300 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.223\n",
      "INFO:tensorflow:loss = 23.313196, step = 2400 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.238\n",
      "INFO:tensorflow:loss = 22.18243, step = 2500 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.222\n",
      "INFO:tensorflow:loss = 26.835983, step = 2600 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.224\n",
      "INFO:tensorflow:loss = 25.833351, step = 2700 (0.444 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2800 into C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmpznihab50\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 28.069845.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-11T15:51:38Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmpznihab50\\model.ckpt-2800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.25002s\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-11-15:51:38\n",
      "INFO:tensorflow:Saving dict for global step 2800: global_step = 2800, loss = 25.903751, mean_absolute_error = 3.27314, mean_squared_error = 25.676477\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2800: C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmpznihab50\\model.ckpt-2800\n",
      "{'loss': 25.903751, 'mean_absolute_error': 3.27314, 'mean_squared_error': 25.676477, 'global_step': 2800}\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = ['CHAS', 'RAD']\n",
    "numeric_cols = ['CRIM', 'ZN', 'INDUS',  'NOX', 'RM', 'AGE', 'DIS', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "feature_columns, feature_layer_inputs = define_feature_columns_layers(data, categorical_cols, numeric_cols)\n",
    "interactions_columns = create_interactions([['RM', 'LSTAT']])\n",
    "\n",
    "feature_columns += interactions_columns\n",
    "\n",
    "optimizer = keras.optimizers.Ftrl(learning_rate=0.02)\n",
    "model = create_ridge_linreg(feature_columns, feature_layer_inputs, optimizer,\n",
    "                      loss='mean_squared_error', \n",
    "                      metrics=['mean_absolute_error', 'mean_squared_error'],\n",
    "                           l2=0.01)\n",
    "\n",
    "estimator = canned_keras(model)\n",
    "\n",
    "train_input_fn = make_input_fn(train, y_train, num_epochs=1400)\n",
    "test_input_fn = make_input_fn(test, y_test, num_epochs=1, shuffle=False)\n",
    "\n",
    "estimator.train(train_input_fn)\n",
    "result = estimator.evaluate(test_input_fn)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lasso_linreg(feature_columns, feature_layer_inputs, optimizer, \n",
    "                        loss='mean_squared_error', metrics=['mean_absolute_error'],\n",
    "                        l1=0.001):\n",
    "    \n",
    "    regularizer = keras.regularizers.l1(l1)\n",
    "\n",
    "    feature_layer = keras.layers.DenseFeatures(feature_columns)\n",
    "    feature_layer_outputs = feature_layer(feature_layer_inputs)\n",
    "    norm = keras.layers.BatchNormalization()(feature_layer_outputs)\n",
    "    outputs = keras.layers.Dense(1, \n",
    "                                 kernel_initializer='normal', \n",
    "                                 kernel_regularizer = regularizer, \n",
    "                                 activation='linear')(norm)\n",
    "    \n",
    "    model = keras.Model(inputs=[v for v in feature_layer_inputs.values()], outputs=outputs)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\LUCAMA~1.AZU\\\\AppData\\\\Local\\\\Temp\\\\tmp9j35shbg', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='C:\\\\Users\\\\LUCAMA~1.AZU\\\\AppData\\\\Local\\\\Temp\\\\tmp9j35shbg\\\\keras\\\\keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp9j35shbg\\keras\\keras_model.ckpt\n",
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n",
      "INFO:tensorflow:Warm-started 4 variables.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp9j35shbg\\model.ckpt.\n",
      "INFO:tensorflow:loss = 616.1925, step = 0\n",
      "INFO:tensorflow:global_step/sec: 197.239\n",
      "INFO:tensorflow:loss = 299.31213, step = 100 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.719\n",
      "INFO:tensorflow:loss = 120.191, step = 200 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.717\n",
      "INFO:tensorflow:loss = 64.74606, step = 300 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.714\n",
      "INFO:tensorflow:loss = 44.16386, step = 400 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.239\n",
      "INFO:tensorflow:loss = 41.137962, step = 500 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.713\n",
      "INFO:tensorflow:loss = 34.268322, step = 600 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.79\n",
      "INFO:tensorflow:loss = 30.289476, step = 700 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.245\n",
      "INFO:tensorflow:loss = 29.681778, step = 800 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.734\n",
      "INFO:tensorflow:loss = 27.94942, step = 900 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.713\n",
      "INFO:tensorflow:loss = 30.039753, step = 1000 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.214\n",
      "INFO:tensorflow:loss = 27.446302, step = 1100 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.734\n",
      "INFO:tensorflow:loss = 26.69628, step = 1200 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.718\n",
      "INFO:tensorflow:loss = 29.125177, step = 1300 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.72\n",
      "INFO:tensorflow:loss = 24.20601, step = 1400 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.214\n",
      "INFO:tensorflow:loss = 25.360537, step = 1500 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.72\n",
      "INFO:tensorflow:loss = 20.759321, step = 1600 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.757\n",
      "INFO:tensorflow:loss = 19.939667, step = 1700 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.734\n",
      "INFO:tensorflow:loss = 26.394392, step = 1800 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.216\n",
      "INFO:tensorflow:loss = 23.13602, step = 1900 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.243\n",
      "INFO:tensorflow:loss = 24.603472, step = 2000 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.226\n",
      "INFO:tensorflow:loss = 20.757122, step = 2100 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.214\n",
      "INFO:tensorflow:loss = 21.666243, step = 2200 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.226\n",
      "INFO:tensorflow:loss = 26.691757, step = 2300 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.717\n",
      "INFO:tensorflow:loss = 18.954304, step = 2400 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.719\n",
      "INFO:tensorflow:loss = 18.901178, step = 2500 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.734\n",
      "INFO:tensorflow:loss = 21.674688, step = 2600 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.758\n",
      "INFO:tensorflow:loss = 23.351412, step = 2700 (0.441 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2800 into C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp9j35shbg\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 25.666773.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-11T15:51:55Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp9j35shbg\\model.ckpt-2800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.25765s\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-11-15:51:56\n",
      "INFO:tensorflow:Saving dict for global step 2800: global_step = 2800, loss = 24.616476, mean_absolute_error = 3.1985352, mean_squared_error = 24.59167\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2800: C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp9j35shbg\\model.ckpt-2800\n",
      "{'loss': 24.616476, 'mean_absolute_error': 3.1985352, 'mean_squared_error': 24.59167, 'global_step': 2800}\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = ['CHAS', 'RAD']\n",
    "numeric_cols = ['CRIM', 'ZN', 'INDUS',  'NOX', 'RM', 'AGE', 'DIS', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "feature_columns, feature_layer_inputs = define_feature_columns_layers(data, categorical_cols, numeric_cols)\n",
    "interactions_columns = create_interactions([['RM', 'LSTAT']])\n",
    "\n",
    "feature_columns += interactions_columns\n",
    "\n",
    "optimizer = keras.optimizers.Ftrl(learning_rate=0.02)\n",
    "model = create_lasso_linreg(feature_columns, feature_layer_inputs, optimizer,\n",
    "                      loss='mean_squared_error', \n",
    "                      metrics=['mean_absolute_error', 'mean_squared_error'],\n",
    "                           l1=0.001)\n",
    "\n",
    "estimator = canned_keras(model)\n",
    "\n",
    "train_input_fn = make_input_fn(train, y_train, num_epochs=1400)\n",
    "test_input_fn = make_input_fn(test, y_test, num_epochs=1, shuffle=False)\n",
    "\n",
    "estimator.train(train_input_fn)\n",
    "result = estimator.evaluate(test_input_fn)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing elastic net regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_elasticnet_linreg(feature_columns, feature_layer_inputs, optimizer, \n",
    "                        loss='mean_squared_error', metrics=['mean_absolute_error'],\n",
    "                        l1=0.001, l2=0.01):\n",
    "    \n",
    "    regularizer = keras.regularizers.l1_l2(l1=l1, l2=l2)\n",
    "\n",
    "    feature_layer = keras.layers.DenseFeatures(feature_columns)\n",
    "    feature_layer_outputs = feature_layer(feature_layer_inputs)\n",
    "    norm = keras.layers.BatchNormalization()(feature_layer_outputs)\n",
    "    outputs = keras.layers.Dense(1, \n",
    "                                 kernel_initializer='normal', \n",
    "                                 kernel_regularizer = regularizer, \n",
    "                                 activation='linear')(norm)\n",
    "    \n",
    "    model = keras.Model(inputs=[v for v in feature_layer_inputs.values()], outputs=outputs)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\LUCAMA~1.AZU\\\\AppData\\\\Local\\\\Temp\\\\tmp45t6ixjc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='C:\\\\Users\\\\LUCAMA~1.AZU\\\\AppData\\\\Local\\\\Temp\\\\tmp45t6ixjc\\\\keras\\\\keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp45t6ixjc\\keras\\keras_model.ckpt\n",
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n",
      "INFO:tensorflow:Warm-started 4 variables.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp45t6ixjc\\model.ckpt.\n",
      "INFO:tensorflow:loss = 630.96313, step = 0\n",
      "INFO:tensorflow:global_step/sec: 195.313\n",
      "INFO:tensorflow:loss = 303.0098, step = 100 (0.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.245\n",
      "INFO:tensorflow:loss = 155.16202, step = 200 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.713\n",
      "INFO:tensorflow:loss = 68.92694, step = 300 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.223\n",
      "INFO:tensorflow:loss = 43.096092, step = 400 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.729\n",
      "INFO:tensorflow:loss = 36.745426, step = 500 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.244\n",
      "INFO:tensorflow:loss = 29.034836, step = 600 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.733\n",
      "INFO:tensorflow:loss = 29.799831, step = 700 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.72\n",
      "INFO:tensorflow:loss = 35.618366, step = 800 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.733\n",
      "INFO:tensorflow:loss = 31.616642, step = 900 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.225\n",
      "INFO:tensorflow:loss = 27.107433, step = 1000 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.757\n",
      "INFO:tensorflow:loss = 27.662424, step = 1100 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.215\n",
      "INFO:tensorflow:loss = 30.326134, step = 1200 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.215\n",
      "INFO:tensorflow:loss = 26.403854, step = 1300 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.214\n",
      "INFO:tensorflow:loss = 28.223143, step = 1400 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.714\n",
      "INFO:tensorflow:loss = 20.657722, step = 1500 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.311\n",
      "INFO:tensorflow:loss = 30.460117, step = 1600 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.215\n",
      "INFO:tensorflow:loss = 22.725325, step = 1700 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.733\n",
      "INFO:tensorflow:loss = 24.092272, step = 1800 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.215\n",
      "INFO:tensorflow:loss = 26.659035, step = 1900 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.273\n",
      "INFO:tensorflow:loss = 19.406818, step = 2000 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.717\n",
      "INFO:tensorflow:loss = 22.650146, step = 2100 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.719\n",
      "INFO:tensorflow:loss = 21.156584, step = 2200 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.215\n",
      "INFO:tensorflow:loss = 25.42233, step = 2300 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.718\n",
      "INFO:tensorflow:loss = 20.21536, step = 2400 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.214\n",
      "INFO:tensorflow:loss = 25.177654, step = 2500 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.222\n",
      "INFO:tensorflow:loss = 19.26351, step = 2600 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.733\n",
      "INFO:tensorflow:loss = 17.540882, step = 2700 (0.443 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2800 into C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp45t6ixjc\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 30.460014.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-11T15:52:13Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp45t6ixjc\\model.ckpt-2800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.25700s\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-11-15:52:13\n",
      "INFO:tensorflow:Saving dict for global step 2800: global_step = 2800, loss = 25.364197, mean_absolute_error = 3.1912956, mean_squared_error = 25.114643\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2800: C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp45t6ixjc\\model.ckpt-2800\n",
      "{'loss': 25.364197, 'mean_absolute_error': 3.1912956, 'mean_squared_error': 25.114643, 'global_step': 2800}\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = ['CHAS', 'RAD']\n",
    "numeric_cols = ['CRIM', 'ZN', 'INDUS',  'NOX', 'RM', 'AGE', 'DIS', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "feature_columns, feature_layer_inputs = define_feature_columns_layers(data, categorical_cols, numeric_cols)\n",
    "interactions_columns = create_interactions([['RM', 'LSTAT']])\n",
    "\n",
    "feature_columns += interactions_columns\n",
    "\n",
    "optimizer = keras.optimizers.Ftrl(learning_rate=0.02)\n",
    "model = create_elasticnet_linreg(feature_columns, feature_layer_inputs, optimizer,\n",
    "                      loss='mean_squared_error', \n",
    "                      metrics=['mean_absolute_error', 'mean_squared_error'],\n",
    "                           l1=0.001, l2=0.01)\n",
    "\n",
    "estimator = canned_keras(model)\n",
    "\n",
    "train_input_fn = make_input_fn(train, y_train, num_epochs=1400)\n",
    "test_input_fn = make_input_fn(test, y_test, num_epochs=1, shuffle=False)\n",
    "\n",
    "estimator.train(train_input_fn)\n",
    "result = estimator.evaluate(test_input_fn)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = 'https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "path = tf.keras.utils.get_file(breast_cancer.split(\"/\")[-1], breast_cancer)\n",
    "\n",
    "columns = ['sample_code', 'clump_thickness', 'cell_size_uniformity', 'cell_shape_uniformity',\n",
    "           'marginal_adhesion', 'single_epithelial_cell_size', 'bare_nuclei', 'bland_chromatin',\n",
    "           'normal_nucleoli', 'mitoses', 'class']\n",
    "\n",
    "data = pd.read_csv(path, header=None, names=columns, na_values=[np.nan, '?'])\n",
    "data = data.fillna(data.median())\n",
    "\n",
    "np.random.seed(1)\n",
    "train = data.sample(frac=0.8).copy()\n",
    "y_train = (train['class']==4).astype(int)\n",
    "train.drop(['sample_code', 'class'], axis=1, inplace=True)\n",
    "\n",
    "test = data.loc[~data.index.isin(train.index)].copy()\n",
    "y_test = (test['class']==4).astype(int)\n",
    "test.drop(['sample_code', 'class'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_logreg(feature_columns, feature_layer_inputs, optimizer, \n",
    "                  loss='binary_crossentropy', metrics=['accuracy'],\n",
    "                  l2=0.01):\n",
    "    \n",
    "    regularizer = keras.regularizers.l2(l2)\n",
    "\n",
    "    feature_layer = keras.layers.DenseFeatures(feature_columns)\n",
    "    feature_layer_outputs = feature_layer(feature_layer_inputs)\n",
    "    norm = keras.layers.BatchNormalization()(feature_layer_outputs)\n",
    "    outputs = keras.layers.Dense(1, \n",
    "                                 kernel_initializer='normal', \n",
    "                                 kernel_regularizer = regularizer, \n",
    "                                 activation='sigmoid')(norm)\n",
    "    \n",
    "    model = keras.Model(inputs=[v for v in feature_layer_inputs.values()], outputs=outputs)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\LUCAMA~1.AZU\\\\AppData\\\\Local\\\\Temp\\\\tmp3g1fr9sj', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='C:\\\\Users\\\\LUCAMA~1.AZU\\\\AppData\\\\Local\\\\Temp\\\\tmp3g1fr9sj\\\\keras\\\\keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp3g1fr9sj\\keras\\keras_model.ckpt\n",
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n",
      "INFO:tensorflow:Warm-started 4 variables.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp3g1fr9sj\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.68767864, step = 0\n",
      "INFO:tensorflow:global_step/sec: 344.826\n",
      "INFO:tensorflow:loss = 0.6782166, step = 100 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.037\n",
      "INFO:tensorflow:loss = 0.52097845, step = 200 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.681\n",
      "INFO:tensorflow:loss = 0.31143478, step = 300 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.031\n",
      "INFO:tensorflow:loss = 0.2078455, step = 400 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.19\n",
      "INFO:tensorflow:loss = 0.39498782, step = 500 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.941\n",
      "INFO:tensorflow:loss = 0.19913399, step = 600 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.503\n",
      "INFO:tensorflow:loss = 0.19563176, step = 700 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.197\n",
      "INFO:tensorflow:loss = 0.17810906, step = 800 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.222\n",
      "INFO:tensorflow:loss = 0.14491706, step = 900 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.223\n",
      "INFO:tensorflow:loss = 0.18246177, step = 1000 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.164\n",
      "INFO:tensorflow:loss = 0.20921467, step = 1100 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.671\n",
      "INFO:tensorflow:loss = 0.10574402, step = 1200 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.522\n",
      "INFO:tensorflow:loss = 0.14822327, step = 1300 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.523\n",
      "INFO:tensorflow:loss = 0.09877187, step = 1400 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.223\n",
      "INFO:tensorflow:loss = 0.08207533, step = 1500 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.668\n",
      "INFO:tensorflow:loss = 0.14005616, step = 1600 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.665\n",
      "INFO:tensorflow:loss = 0.13449185, step = 1700 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.524\n",
      "INFO:tensorflow:loss = 0.2613508, step = 1800 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.78\n",
      "INFO:tensorflow:loss = 0.068801895, step = 1900 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.944\n",
      "INFO:tensorflow:loss = 0.1429057, step = 2000 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.782\n",
      "INFO:tensorflow:loss = 0.10475543, step = 2100 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.901\n",
      "INFO:tensorflow:loss = 0.0877016, step = 2200 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.257\n",
      "INFO:tensorflow:loss = 0.12374037, step = 2300 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.663\n",
      "INFO:tensorflow:loss = 0.10116844, step = 2400 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.648\n",
      "INFO:tensorflow:loss = 0.1621183, step = 2500 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.617\n",
      "INFO:tensorflow:loss = 0.13121274, step = 2600 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.856\n",
      "INFO:tensorflow:loss = 0.14180051, step = 2700 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.036\n",
      "INFO:tensorflow:loss = 0.09512355, step = 2800 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.533\n",
      "INFO:tensorflow:loss = 0.06992111, step = 2900 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.531\n",
      "INFO:tensorflow:loss = 0.075731665, step = 3000 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.942\n",
      "INFO:tensorflow:loss = 0.19326453, step = 3100 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.035\n",
      "INFO:tensorflow:loss = 0.10250812, step = 3200 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.352\n",
      "INFO:tensorflow:loss = 0.06906183, step = 3300 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.527\n",
      "INFO:tensorflow:loss = 0.16956922, step = 3400 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.534\n",
      "INFO:tensorflow:loss = 0.13456212, step = 3500 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.753\n",
      "INFO:tensorflow:loss = 0.06462775, step = 3600 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.783\n",
      "INFO:tensorflow:loss = 0.09151909, step = 3700 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.939\n",
      "INFO:tensorflow:loss = 0.06757977, step = 3800 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.353\n",
      "INFO:tensorflow:loss = 0.16729525, step = 3900 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.222\n",
      "INFO:tensorflow:loss = 0.12930852, step = 4000 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.528\n",
      "INFO:tensorflow:loss = 0.046706513, step = 4100 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.354\n",
      "INFO:tensorflow:loss = 0.103456385, step = 4200 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.035\n",
      "INFO:tensorflow:loss = 0.34504038, step = 4300 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.73\n",
      "INFO:tensorflow:loss = 0.09262861, step = 4400 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.347\n",
      "INFO:tensorflow:loss = 0.07900547, step = 4500 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.188\n",
      "INFO:tensorflow:loss = 0.14289299, step = 4600 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.184\n",
      "INFO:tensorflow:loss = 0.12745047, step = 4700 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.532\n",
      "INFO:tensorflow:loss = 0.1272218, step = 4800 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.532\n",
      "INFO:tensorflow:loss = 0.07698923, step = 4900 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.783\n",
      "INFO:tensorflow:loss = 0.16909267, step = 5000 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.35\n",
      "INFO:tensorflow:loss = 0.055070642, step = 5100 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.521\n",
      "INFO:tensorflow:loss = 0.048407674, step = 5200 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.859\n",
      "INFO:tensorflow:loss = 0.19250461, step = 5300 (0.247 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5400 into C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp3g1fr9sj\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.09771245.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-11T15:52:30Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp3g1fr9sj\\model.ckpt-5400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.24300s\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-11-15:52:31\n",
      "INFO:tensorflow:Saving dict for global step 5400: accuracy = 0.94285715, global_step = 5400, loss = 0.16691028\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5400: C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp3g1fr9sj\\model.ckpt-5400\n",
      "{'accuracy': 0.94285715, 'loss': 0.16691028, 'global_step': 5400}\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = []\n",
    "numeric_cols = ['clump_thickness', 'cell_size_uniformity', 'cell_shape_uniformity',\n",
    "                'marginal_adhesion', 'single_epithelial_cell_size', 'bare_nuclei', 'bland_chromatin',\n",
    "                'normal_nucleoli', 'mitoses']\n",
    "\n",
    "feature_columns, feature_layer_inputs = define_feature_columns_layers(data, categorical_cols, numeric_cols)\n",
    "\n",
    "optimizer = keras.optimizers.Ftrl(learning_rate=0.02)\n",
    "model = create_logreg(feature_columns, feature_layer_inputs, optimizer, l2=0.01)\n",
    "\n",
    "estimator = canned_keras(model)\n",
    "\n",
    "train_input_fn = make_input_fn(train, y_train, num_epochs=300, batch_size=32)\n",
    "test_input_fn = make_input_fn(test, y_test, num_epochs=1, shuffle=False)\n",
    "\n",
    "estimator.train(train_input_fn)\n",
    "result = estimator.evaluate(test_input_fn)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resorting to non-linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from tensorflow.python.keras.layers.kernelized import RandomFourierFeatures\n",
    "except:\n",
    "    # from TF 2.2\n",
    "    from tensorflow.keras.layers.experimental import RandomFourierFeatures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_svc(feature_columns, feature_layer_inputs, optimizer, \n",
    "               loss='hinge', metrics=['accuracy'],\n",
    "               l2=0.01, output_dim=64, scale=None):\n",
    "    \n",
    "    regularizer = keras.regularizers.l2(l2)\n",
    "\n",
    "    feature_layer = keras.layers.DenseFeatures(feature_columns)\n",
    "    feature_layer_outputs = feature_layer(feature_layer_inputs)\n",
    "    norm = keras.layers.BatchNormalization()(feature_layer_outputs)\n",
    "    rff = RandomFourierFeatures(output_dim=output_dim, scale=scale, kernel_initializer='gaussian')(norm)\n",
    "    outputs = keras.layers.Dense(1, \n",
    "                                 kernel_initializer='normal', \n",
    "                                 kernel_regularizer = regularizer, \n",
    "                                 activation='sigmoid')(rff)\n",
    "    \n",
    "    model = keras.Model(inputs=[v for v in feature_layer_inputs.values()], outputs=outputs)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:From C:\\Users\\LucaMassaron.AzureAD\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\kernelized.py:187: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\LUCAMA~1.AZU\\\\AppData\\\\Local\\\\Temp\\\\tmprrf7djzy', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='C:\\\\Users\\\\LUCAMA~1.AZU\\\\AppData\\\\Local\\\\Temp\\\\tmprrf7djzy\\\\keras\\\\keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmprrf7djzy\\keras\\keras_model.ckpt\n",
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n",
      "INFO:tensorflow:Warm-started 5 variables.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmprrf7djzy\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.201552, step = 0\n",
      "INFO:tensorflow:global_step/sec: 341.3\n",
      "INFO:tensorflow:loss = 0.7867329, step = 100 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.936\n",
      "INFO:tensorflow:loss = 0.66063976, step = 200 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.408\n",
      "INFO:tensorflow:loss = 0.7666702, step = 300 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.522\n",
      "INFO:tensorflow:loss = 0.59589523, step = 400 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.169\n",
      "INFO:tensorflow:loss = 0.7594504, step = 500 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.941\n",
      "INFO:tensorflow:loss = 0.85102797, step = 600 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.409\n",
      "INFO:tensorflow:loss = 0.7914205, step = 700 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.94\n",
      "INFO:tensorflow:loss = 0.63128024, step = 800 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.731\n",
      "INFO:tensorflow:loss = 0.7616837, step = 900 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.167\n",
      "INFO:tensorflow:loss = 0.6613934, step = 1000 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.941\n",
      "INFO:tensorflow:loss = 0.6927883, step = 1100 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.728\n",
      "INFO:tensorflow:loss = 0.8195445, step = 1200 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.94\n",
      "INFO:tensorflow:loss = 0.6623598, step = 1300 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.17\n",
      "INFO:tensorflow:loss = 0.5996184, step = 1400 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.409\n",
      "INFO:tensorflow:loss = 0.75621074, step = 1500 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.942\n",
      "INFO:tensorflow:loss = 0.66305375, step = 1600 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.665\n",
      "INFO:tensorflow:loss = 0.8384055, step = 1700 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.86\n",
      "INFO:tensorflow:loss = 0.7610958, step = 1800 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.835\n",
      "INFO:tensorflow:loss = 0.6709981, step = 1900 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.699\n",
      "INFO:tensorflow:loss = 0.7855014, step = 2000 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.837\n",
      "INFO:tensorflow:loss = 0.6688878, step = 2100 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.94\n",
      "INFO:tensorflow:loss = 0.5704346, step = 2200 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.186\n",
      "INFO:tensorflow:loss = 0.7265024, step = 2300 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.53\n",
      "INFO:tensorflow:loss = 0.69021446, step = 2400 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.188\n",
      "INFO:tensorflow:loss = 0.66797084, step = 2500 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.348\n",
      "INFO:tensorflow:loss = 0.6654261, step = 2600 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.412\n",
      "INFO:tensorflow:loss = 0.66713554, step = 2700 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.183\n",
      "INFO:tensorflow:loss = 0.61170197, step = 2800 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.725\n",
      "INFO:tensorflow:loss = 0.67414135, step = 2900 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.733\n",
      "INFO:tensorflow:loss = 0.756, step = 3000 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.35\n",
      "INFO:tensorflow:loss = 0.6653724, step = 3100 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.533\n",
      "INFO:tensorflow:loss = 0.8519637, step = 3200 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.728\n",
      "INFO:tensorflow:loss = 0.610377, step = 3300 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.531\n",
      "INFO:tensorflow:loss = 0.7332215, step = 3400 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.901\n",
      "INFO:tensorflow:loss = 0.60130554, step = 3500 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.532\n",
      "INFO:tensorflow:loss = 0.7318238, step = 3600 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.35\n",
      "INFO:tensorflow:loss = 0.7397925, step = 3700 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.723\n",
      "INFO:tensorflow:loss = 0.85353285, step = 3800 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.905\n",
      "INFO:tensorflow:loss = 0.7876065, step = 3900 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.941\n",
      "INFO:tensorflow:loss = 0.63702875, step = 4000 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.167\n",
      "INFO:tensorflow:loss = 0.72562355, step = 4100 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.165\n",
      "INFO:tensorflow:loss = 0.7297971, step = 4200 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.895\n",
      "INFO:tensorflow:loss = 0.58583415, step = 4300 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.944\n",
      "INFO:tensorflow:loss = 0.7288042, step = 4400 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.186\n",
      "INFO:tensorflow:loss = 0.68310636, step = 4500 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.033\n",
      "INFO:tensorflow:loss = 0.6655797, step = 4600 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.729\n",
      "INFO:tensorflow:loss = 0.6365467, step = 4700 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.533\n",
      "INFO:tensorflow:loss = 0.83205545, step = 4800 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.184\n",
      "INFO:tensorflow:loss = 0.605943, step = 4900 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.185\n",
      "INFO:tensorflow:loss = 0.58465934, step = 5000 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.532\n",
      "INFO:tensorflow:loss = 0.733313, step = 5100 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.033\n",
      "INFO:tensorflow:loss = 0.7336465, step = 5200 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.901\n",
      "INFO:tensorflow:loss = 0.6754761, step = 5300 (0.232 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5400 into C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmprrf7djzy\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.7652148.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-11T15:52:48Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmprrf7djzy\\model.ckpt-5400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.24489s\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-11-15:52:48\n",
      "INFO:tensorflow:Saving dict for global step 5400: accuracy = 0.9357143, global_step = 5400, loss = 0.71555066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5400: C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmprrf7djzy\\model.ckpt-5400\n",
      "{'accuracy': 0.9357143, 'loss': 0.71555066, 'global_step': 5400}\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = []\n",
    "numeric_cols = ['clump_thickness', 'cell_size_uniformity', 'cell_shape_uniformity',\n",
    "                'marginal_adhesion', 'single_epithelial_cell_size', 'bare_nuclei', 'bland_chromatin',\n",
    "                'normal_nucleoli', 'mitoses']\n",
    "\n",
    "feature_columns, feature_layer_inputs = define_feature_columns_layers(data, categorical_cols, numeric_cols)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model = create_svc(feature_columns, feature_layer_inputs, optimizer, \n",
    "                   loss='hinge', l2=0.001, output_dim=512)\n",
    "\n",
    "estimator = canned_keras(model)\n",
    "\n",
    "train_input_fn = make_input_fn(train, y_train, num_epochs=300, batch_size=32)\n",
    "test_input_fn = make_input_fn(test, y_test, num_epochs=1, shuffle=False)\n",
    "\n",
    "estimator.train(train_input_fn)\n",
    "result = estimator.evaluate(test_input_fn)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Wide & Deep Learning for Recommender Systems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_dir = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/'\n",
    "train_path = tf.keras.utils.get_file('adult.data', census_dir + 'adult.data')\n",
    "test_path = tf.keras.utils.get_file('adult.test', census_dir + 'adult.test')\n",
    "\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
    "           'marital_status', 'occupation', 'relationship', 'race', 'gender',\n",
    "           'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "           'income_bracket']\n",
    "\n",
    "train_data = pd.read_csv(train_path, header=None, names=columns)\n",
    "test_data = pd.read_csv(test_path, header=None, names=columns, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['age', 'workclass', 'education', 'education_num',\n",
    "              'marital_status', 'occupation', 'relationship', 'gender']\n",
    "\n",
    "y_train = (train_data.income_bracket==' >50K').astype(int)\n",
    "y_test = (test_data.income_bracket==' >50K.').astype(int)\n",
    "\n",
    "train_data = train_data[predictors]\n",
    "test_data = test_data[predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[['age', 'education_num']] = train_data[['age', 'education_num']].fillna(train_data[['age', 'education_num']].mean())\n",
    "test_data[['age', 'education_num']] = test_data[['age', 'education_num']].fillna(train_data[['age', 'education_num']].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_feature_columns(data_df, numeric_cols, categorical_cols, categorical_embeds, dimension=30):\n",
    "    numeric_columns = []\n",
    "    categorical_columns = []\n",
    "    embeddings = []\n",
    "    \n",
    "    for feature_name in numeric_cols:\n",
    "        numeric_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
    "    \n",
    "    for feature_name in categorical_cols:\n",
    "        vocabulary = data_df[feature_name].unique()\n",
    "        categorical_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "        \n",
    "    for feature_name in categorical_embeds:\n",
    "        vocabulary = data_df[feature_name].unique()\n",
    "        to_categorical = tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)\n",
    "        embeddings.append(tf.feature_column.embedding_column(to_categorical, dimension=dimension))\n",
    "        \n",
    "    return numeric_columns, categorical_columns, embeddings\n",
    "\n",
    "def create_interactions(interactions_list, buckets=10):\n",
    "    feature_columns = []\n",
    "    \n",
    "    for (a, b) in interactions_list:\n",
    "        crossed_feature = tf.feature_column.crossed_column([a, b], hash_bucket_size=buckets)\n",
    "        crossed_feature_one_hot = tf.feature_column.indicator_column(crossed_feature)\n",
    "        feature_columns.append(crossed_feature_one_hot)\n",
    "        \n",
    "    return feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns, categorical_columns, embeddings = define_feature_columns(train_data, \n",
    "                                                                          numeric_cols=['age', 'education_num'], \n",
    "                                                                          categorical_cols=['gender'], \n",
    "                                                                          categorical_embeds=['workclass', 'education',\n",
    "                                                                                              'marital_status', 'occupation', \n",
    "                                                                                              'relationship'], \n",
    "                                                                          dimension=32)\n",
    "\n",
    "interactions = create_interactions([['education', 'occupation']], buckets=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp25oxd1at\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\LUCAMA~1.AZU\\\\AppData\\\\Local\\\\Temp\\\\tmp25oxd1at', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.DNNLinearCombinedClassifier(\n",
    "    # wide settings\n",
    "    linear_feature_columns=numeric_columns+categorical_columns+interactions,\n",
    "    linear_optimizer=keras.optimizers.Ftrl(learning_rate=0.02),\n",
    "    # deep settings\n",
    "    dnn_feature_columns=embeddings,\n",
    "    dnn_hidden_units=[1024, 512, 128, 64],\n",
    "    dnn_optimizer=keras.optimizers.Adam(learning_rate=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=256):\n",
    "    \n",
    "    def input_function():\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000)\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "        return ds\n",
    "    \n",
    "    return input_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = make_input_fn(train_data, y_train, num_epochs=500, batch_size=256)\n",
    "test_input_fn = make_input_fn(test_data, y_test, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp25oxd1at\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.6887884, step = 0\n",
      "INFO:tensorflow:global_step/sec: 57.1429\n",
      "INFO:tensorflow:loss = 0.37364495, step = 100 (1.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.8502\n",
      "INFO:tensorflow:loss = 0.40053362, step = 200 (1.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.6268\n",
      "INFO:tensorflow:loss = 0.40525287, step = 300 (1.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.0752\n",
      "INFO:tensorflow:loss = 0.28332102, step = 400 (1.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.9625\n",
      "INFO:tensorflow:loss = 0.34983099, step = 500 (1.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.7943\n",
      "INFO:tensorflow:loss = 0.38028675, step = 600 (1.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.9625\n",
      "INFO:tensorflow:loss = 0.35195953, step = 700 (1.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.7383\n",
      "INFO:tensorflow:loss = 0.3538752, step = 800 (1.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.6269\n",
      "INFO:tensorflow:loss = 0.37966532, step = 900 (1.341 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp25oxd1at\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.3291218.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn_linear_combined.DNNLinearCombinedClassifierV2 at 0x2221f407b38>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-11T15:53:21Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp25oxd1at\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 2.24300s\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-11-15:53:23\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.83391684, accuracy_baseline = 0.76377374, auc = 0.88012385, auc_precision_recall = 0.68032277, average_loss = 0.35969484, global_step = 1000, label/mean = 0.23622628, loss = 0.35985297, precision = 0.70583993, prediction/mean = 0.21803579, recall = 0.5091004\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp25oxd1at\\model.ckpt-1000\n",
      "{'accuracy': 0.83391684, 'accuracy_baseline': 0.76377374, 'auc': 0.88012385, 'auc_precision_recall': 0.68032277, 'average_loss': 0.35969484, 'label/mean': 0.23622628, 'loss': 0.35985297, 'precision': 0.70583993, 'prediction/mean': 0.21803579, 'recall': 0.5091004, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "results = estimator.evaluate(input_fn=test_input_fn)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\LUCAMA~1.AZU\\AppData\\Local\\Temp\\tmp25oxd1at\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "def predict_proba(predictor):\n",
    "    preds = list()\n",
    "    for pred in predictor:\n",
    "        preds.append(pred['probabilities'])\n",
    "    return np.array(preds)\n",
    "\n",
    "predictions = predict_proba(estimator.predict(input_fn=test_input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9922061e-01, 7.7938952e-04],\n",
       "       [8.7542838e-01, 1.2457163e-01],\n",
       "       [3.6073923e-01, 6.3926083e-01],\n",
       "       ...,\n",
       "       [2.7226123e-01, 7.2773874e-01],\n",
       "       [9.3168575e-01, 6.8314269e-02],\n",
       "       [3.0533168e-01, 6.9466835e-01]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
