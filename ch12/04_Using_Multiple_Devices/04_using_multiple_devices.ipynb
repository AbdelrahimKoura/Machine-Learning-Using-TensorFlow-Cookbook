{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KPo4692KTNvc"
   },
   "source": [
    "# Using Multiple devices\n",
    "\n",
    "An easy way to have a GPU is to run the code in Google Colab and set GPU as the hardware accelerator in the notebook settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2358,
     "status": "ok",
     "timestamp": 1601104038895,
     "user": {
      "displayName": "Alexia Audevart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggwako-F982wqMhMKBGTSz7xNQvuu4pmC79syucvA=s64",
      "userId": "09723170522858788865"
     },
     "user_tz": -120
    },
    "id": "qvtaetE0TNvd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3655,
     "status": "ok",
     "timestamp": 1601104040202,
     "user": {
      "displayName": "Alexia Audevart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggwako-F982wqMhMKBGTSz7xNQvuu4pmC79syucvA=s64",
      "userId": "09723170522858788865"
     },
     "user_tz": -120
    },
    "id": "WShhcn92TNvg",
    "outputId": "58885c06-46e8-4300-ec01-4628abf15578"
   },
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dLx_JoDFTNvk"
   },
   "source": [
    "## Find out where placement occurs\n",
    "\n",
    "If a TensorFlow operation is implemented for CPU and GPU devices, the operation will be executed by default on a GPU device if a GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3282,
     "status": "ok",
     "timestamp": 1601103854192,
     "user": {
      "displayName": "Alexia Audevart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggwako-F982wqMhMKBGTSz7xNQvuu4pmC79syucvA=s64",
      "userId": "09723170522858788865"
     },
     "user_tz": -120
    },
    "id": "AehjcrN8TNvk",
    "outputId": "7c021a49-0b7e-47c8-a6cf-186d366ca7cf"
   },
   "outputs": [],
   "source": [
    "# To find out where placement occurs, set 'log_device_placement'\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lrFpeKpCTNvm"
   },
   "source": [
    "We can also use the tensor `device` attribute that returns the name of the device on which this tensor will be assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3276,
     "status": "ok",
     "timestamp": 1601103854193,
     "user": {
      "displayName": "Alexia Audevart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggwako-F982wqMhMKBGTSz7xNQvuu4pmC79syucvA=s64",
      "userId": "09723170522858788865"
     },
     "user_tz": -120
    },
    "id": "IHRue5i9TNvn",
    "outputId": "9c7af1eb-ecfd-452f-fa59-e2f2af187acb"
   },
   "outputs": [],
   "source": [
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "print(a.device)\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "print(b.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_MakEc47TNvp"
   },
   "source": [
    "## Create a device context\n",
    "\n",
    "We can select the device to use by creating a device context through the `with tf.device` function.\n",
    "Each operation executed in this context will use the selected device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3269,
     "status": "ok",
     "timestamp": 1601103854194,
     "user": {
      "displayName": "Alexia Audevart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggwako-F982wqMhMKBGTSz7xNQvuu4pmC79syucvA=s64",
      "userId": "09723170522858788865"
     },
     "user_tz": -120
    },
    "id": "4afJYTFiTNvq",
    "outputId": "3a786bc3-a1bc-479a-b9d2-6b2dfb418827"
   },
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "with tf.device('/device:CPU:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9OlP2tSTNvs"
   },
   "source": [
    "If we move the `matmul` operation out of the context. This operation will be executed on a GPU device if it's available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3262,
     "status": "ok",
     "timestamp": 1601103854194,
     "user": {
      "displayName": "Alexia Audevart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggwako-F982wqMhMKBGTSz7xNQvuu4pmC79syucvA=s64",
      "userId": "09723170522858788865"
     },
     "user_tz": -120
    },
    "id": "c0ClsH2mTNvs",
    "outputId": "f44dd974-1727-4179-9de2-ca1343c991dc"
   },
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "with tf.device('/device:CPU:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mvQS_fphTNvv"
   },
   "source": [
    "## Limit the GPU memory allocation\n",
    "Careful with GPU memory allocation, TensorFlow never releases it.  TensorFlow starts with almost\n",
    "all of the GPU memory allocated.  \n",
    "\n",
    "We can slowly grow to that limit with the `tf.config.experimental.set_memory_growth` method option setting or another solution is to set the environmental variable `TF_FORCE_GPU_ALLOW_GROWTH` to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3255,
     "status": "ok",
     "timestamp": 1601103854195,
     "user": {
      "displayName": "Alexia Audevart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggwako-F982wqMhMKBGTSz7xNQvuu4pmC79syucvA=s64",
      "userId": "09723170522858788865"
     },
     "user_tz": -120
    },
    "id": "dn8NCGARTNvv",
    "outputId": "824a285b-c914-4873-dce5-eb681e486991"
   },
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth cannot be modified after GPU has been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yKD30BsITNvx"
   },
   "source": [
    "We can also create a virtual GPU device  with `tf.config.experimental.set_virtual_device_configuration` and set the maximum memory limit (in MB) to allocate on this virtual GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3248,
     "status": "ok",
     "timestamp": 1601103854196,
     "user": {
      "displayName": "Alexia Audevart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggwako-F982wqMhMKBGTSz7xNQvuu4pmC79syucvA=s64",
      "userId": "09723170522858788865"
     },
     "user_tz": -120
    },
    "id": "jKcwcnltTNvy",
    "outputId": "5d12ce1c-8719-4b30-dbc8-86857d16116a"
   },
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpu_devices[0],\n",
    "                                                   [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth cannot be modified after GPU has been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O9QPhCzlTNv0"
   },
   "source": [
    "# Using multiple GPUs\n",
    "\n",
    "We can set placements on multiple devices.\n",
    "Here, assume we have three devices CPU:0, GPU:0, and GPU:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9305,
     "status": "ok",
     "timestamp": 1601104045861,
     "user": {
      "displayName": "Alexia Audevart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggwako-F982wqMhMKBGTSz7xNQvuu4pmC79syucvA=s64",
      "userId": "09723170522858788865"
     },
     "user_tz": -120
    },
    "id": "SzdBn80sTNv1",
    "outputId": "eef64401-c89f-41e7-c2c4-6dc804b294bb"
   },
   "outputs": [],
   "source": [
    "# Create two virtual GPUs\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "if gpu_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpu_devices[0],\n",
    "                                                   [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024),\n",
    "                                                    tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024) ])\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth cannot be modified after GPU has been initialized\n",
    "        print(e)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_logical_devices('GPU')))\n",
    "\n",
    "if tf.test.is_built_with_cuda():\n",
    "    with tf.device('/cpu:0'):\n",
    "        a = tf.constant([1.0, 3.0, 5.0], shape=[1, 3])\n",
    "        b = tf.constant([2.0, 4.0, 6.0], shape=[3, 1])\n",
    "        \n",
    "        with tf.device('/gpu:0'):\n",
    "            c = tf.matmul(a,b)\n",
    "            c = tf.reshape(c, [-1])\n",
    "        \n",
    "        with tf.device('/gpu:1'):\n",
    "            d = tf.matmul(b,a)\n",
    "            flat_d = tf.reshape(d, [-1])\n",
    "        \n",
    "        combined = tf.multiply(c, flat_d)\n",
    "    print(combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3234,
     "status": "ok",
     "timestamp": 1601103854197,
     "user": {
      "displayName": "Alexia Audevart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggwako-F982wqMhMKBGTSz7xNQvuu4pmC79syucvA=s64",
      "userId": "09723170522858788865"
     },
     "user_tz": -120
    },
    "id": "F45O8whtVKxZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "04_using_multiple_devices.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
